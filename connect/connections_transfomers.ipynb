{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "retriever = SentenceTransformer(\n",
    "    \"paraphrase-MiniLM-L6-v2\",\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The first letter of the English and of many ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The name of the sixth tone in the model major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An adjective commonly called the indefinite ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In each; to or for each; as \"\"\"\"twenty leagues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>prep.</td>\n",
       "      <td>In; on; at; by.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175718</th>\n",
       "      <td>Zymotic</td>\n",
       "      <td>a.</td>\n",
       "      <td>Of pertaining to or caused by fermentation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175719</th>\n",
       "      <td>Zymotic</td>\n",
       "      <td>a.</td>\n",
       "      <td>Designating or pertaining to a certain class o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175720</th>\n",
       "      <td>Zythem</td>\n",
       "      <td>n.</td>\n",
       "      <td>See Zythum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175721</th>\n",
       "      <td>Zythepsary</td>\n",
       "      <td>n.</td>\n",
       "      <td>A brewery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175722</th>\n",
       "      <td>Zythum</td>\n",
       "      <td>n.</td>\n",
       "      <td>A kind of ancient malt beverage; a liquor made...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175723 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word    POS                                         Definition\n",
       "0                A    NaN  The first letter of the English and of many ot...\n",
       "1                A    NaN  The name of the sixth tone in the model major ...\n",
       "2                A    NaN  An adjective commonly called the indefinite ar...\n",
       "3                A    NaN  In each; to or for each; as \"\"\"\"twenty leagues...\n",
       "4                A  prep.                                    In; on; at; by.\n",
       "...            ...    ...                                                ...\n",
       "175718     Zymotic     a.        Of pertaining to or caused by fermentation.\n",
       "175719     Zymotic     a.  Designating or pertaining to a certain class o...\n",
       "175720      Zythem     n.                                        See Zythum.\n",
       "175721  Zythepsary     n.                                         A brewery.\n",
       "175722      Zythum     n.  A kind of ancient malt beverage; a liquor made...\n",
       "\n",
       "[175723 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df = pd.read_csv(\"data/dictionary.csv\")\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"PLUTO\", \"RAY\", \"SPONGE\", \"SQUID\", \n",
    "    \"CIRCLE\", \"DIAMOND\", \"SQUARE\", \"TRIANGLE\",\n",
    "    \"BOB\", \"CROSS\", \"HOOK\", \"WEAVE\",\n",
    "    \"FEAST\", \"FREE\", \"PANTS\", \"THAT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df[\"Word\"] = dict_df[\"Word\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = dict_df[dict_df[\"Word\"].isin(words)]\n",
    "\n",
    "dict_df = dict_df.reset_index()\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df['word_number'] = dict_df.groupby('Word').cumcount() + 1\n",
    "\n",
    "dict_df['Word'] = dict_df.apply(lambda row: f\"{row['Word']}_{row['word_number']}\", axis=1)\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = retriever.encode(dict_df['Definition'])\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a,b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "\n",
    "for i in range(len(matrix)):\n",
    "    a = matrix[i]\n",
    "    for j in range(i, len(matrix)):\n",
    "        b = matrix[j]\n",
    "        word1 = dict_df.iloc[i][\"Word\"]\n",
    "        word2 = dict_df.iloc[j][\"Word\"]\n",
    "        if word1[0: word1.index(\"_\")] != word2[0: word2.index(\"_\")]:\n",
    "            similarities.append([dict_df.iloc[i][\"Word\"], dict_df.iloc[j][\"Word\"], cosine_similarity(a, b)/math.dist(a, b)])\n",
    "            \n",
    "df = pd.DataFrame(similarities, columns=[\"word_1\", \"word_2\", \"similarity\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "df = df.sort_values(by=\"similarity\", ascending=False)\n",
    "\n",
    "df[df[\"similarity\"] > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {}\n",
    "\n",
    "for i, n in df.iterrows():\n",
    "    word1 = n[\"word_1\"]\n",
    "    word2 = n[\"word_2\"]\n",
    "    \n",
    "    key1 = (word1, word2)\n",
    "    key2 = (word2, word1)\n",
    "    \n",
    "    relation_dict[key1] = n[\"similarity\"]\n",
    "    relation_dict[key2] = n[\"similarity\"]\n",
    "\n",
    "relation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_4(a, b, c, d):\n",
    "    return relation_dict[(a, b)] + relation_dict[(a, c)] + relation_dict[(a, d)] + relation_dict[(b, c)] + relation_dict[(b, d)] + relation_dict[(c, d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def check_overlap(combo):\n",
    "    w1 = combo[0]\n",
    "    w1 = w1[0: w1.index(\"_\")].strip()\n",
    "    w2 = combo[1]\n",
    "    w2 = w2[0: w2.index(\"_\")].strip() \n",
    "    w3 = combo[2]\n",
    "    w3 = w3[0: w3.index(\"_\")].strip() \n",
    "    w4 = combo[3]\n",
    "    w4 = w4[0: w4.index(\"_\")].strip() \n",
    "    \n",
    "    return not (w1 == w2 or w1 == w3 or w1 == w4 or w2 == w3 or w2 == w4 or w3 == w4)\n",
    "\n",
    "sim_4 = []\n",
    "\n",
    "specified_words = dict_df[\"Word\"]\n",
    "\n",
    "specified_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def similarity_4(a, b, c, d):\n",
    "    return relation_dict[(a, b)] + relation_dict[(a, c)] + relation_dict[(a, d)] + relation_dict[(b, c)] + relation_dict[(b, d)] + relation_dict[(c, d)]\n",
    "\n",
    "sim_scores = {}\n",
    "for i, a in enumerate(specified_words):\n",
    "    for j in range(i + 1, len(specified_words)):\n",
    "        b = specified_words[j]\n",
    "        if a[0:a.index(\"_\")] == b[0:b.index(\"_\")]:\n",
    "            continue\n",
    "        for k in range(j + 1, len(specified_words)):\n",
    "            c = specified_words[k]\n",
    "            if a[0:a.index(\"_\")] == c[0:c.index(\"_\")] or b[0:b.index(\"_\")] == c[0:c.index(\"_\")]:\n",
    "                continue\n",
    "            for l in range(k + 1, len(specified_words)):\n",
    "                d = specified_words[l]\n",
    "                if a[0:a.index(\"_\")] == d[0:d.index(\"_\")] or b[0:b.index(\"_\")] == d[0:d.index(\"_\")] or c[0:c.index(\"_\")] == d[0:d.index(\"_\")]:\n",
    "                    continue\n",
    "                \n",
    "                sim_scores[(a, b, c, d)] = similarity_4(a, b, c, d)\n",
    "\n",
    "sim_heap = []\n",
    "for (a, b, c, d), score in sim_scores.items():\n",
    "    heapq.heappush(sim_heap, (score, [a, b, c, d]))\n",
    "\n",
    "result = heapq.nlargest(10, sim_heap)  # Adjust the number of results as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = heapq.nlargest(10, sim_heap) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removals = result[0][1]\n",
    "\n",
    "for word in removals:\n",
    "    specified_words = [word1 for word1 in specified_words if word[0:word.index(\"_\")] != word1[0:word1.index(\"_\")]]\n",
    "    \n",
    "specified_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = {}\n",
    "for i, a in enumerate(specified_words):\n",
    "    for j in range(i + 1, len(specified_words)):\n",
    "        b = specified_words[j]\n",
    "        if a[0:a.index(\"_\")] == b[0:b.index(\"_\")]:\n",
    "            continue\n",
    "        for k in range(j + 1, len(specified_words)):\n",
    "            c = specified_words[k]\n",
    "            if a[0:a.index(\"_\")] == c[0:c.index(\"_\")] or b[0:b.index(\"_\")] == c[0:c.index(\"_\")]:\n",
    "                continue\n",
    "            for l in range(k + 1, len(specified_words)):\n",
    "                d = specified_words[l]\n",
    "                if a[0:a.index(\"_\")] == d[0:d.index(\"_\")] or b[0:b.index(\"_\")] == d[0:d.index(\"_\")] or c[0:c.index(\"_\")] == d[0:d.index(\"_\")]:\n",
    "                    continue\n",
    "                \n",
    "                sim_scores[(a, b, c, d)] = similarity_4(a, b, c, d)\n",
    "\n",
    "sim_heap = []\n",
    "for (a, b, c, d), score in sim_scores.items():\n",
    "    heapq.heappush(sim_heap, (score, [a, b, c, d]))\n",
    "\n",
    "result = heapq.nlargest(10, sim_heap)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removals = result[2][1]\n",
    "\n",
    "for word in removals:\n",
    "    specified_words = [word1 for word1 in specified_words if word[0:word.index(\"_\")] != word1[0:word1.index(\"_\")]]\n",
    "    \n",
    "specified_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = {}\n",
    "for i, a in enumerate(specified_words):\n",
    "    for j in range(i + 1, len(specified_words)):\n",
    "        b = specified_words[j]\n",
    "        if a[0:a.index(\"_\")] == b[0:b.index(\"_\")]:\n",
    "            continue\n",
    "        for k in range(j + 1, len(specified_words)):\n",
    "            c = specified_words[k]\n",
    "            if a[0:a.index(\"_\")] == c[0:c.index(\"_\")] or b[0:b.index(\"_\")] == c[0:c.index(\"_\")]:\n",
    "                continue\n",
    "            for l in range(k + 1, len(specified_words)):\n",
    "                d = specified_words[l]\n",
    "                if a[0:a.index(\"_\")] == d[0:d.index(\"_\")] or b[0:b.index(\"_\")] == d[0:d.index(\"_\")] or c[0:c.index(\"_\")] == d[0:d.index(\"_\")]:\n",
    "                    continue\n",
    "                \n",
    "                sim_scores[(a, b, c, d)] = similarity_4(a, b, c, d)\n",
    "\n",
    "sim_heap = []\n",
    "for (a, b, c, d), score in sim_scores.items():\n",
    "    heapq.heappush(sim_heap, (score, [a, b, c, d]))\n",
    "\n",
    "result = heapq.nlargest(20, sim_heap)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
